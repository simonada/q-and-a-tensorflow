{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from itertools import chain\n",
    "from InputPreparator import EmbeddingsPreparator\n",
    "from InputPreparator import StoryParser\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_file = get_task_files(10)[0]\n",
    "test_set_file = get_task_files(10)[1]\n",
    "\n",
    "train_set_post_file = \"tasks_1-20_v1-2/en/\"+train_set_file\n",
    "test_set_post_file = \"tasks_1-20_v1-2/en/\"+test_set_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_task_files(task_nr):\n",
    "    if task_nr==5:\n",
    "        return 'qa5_three-arg-relations_train.txt', \"qa5_three-arg-relations_test.txt\"\n",
    "    if task_nr==6:\n",
    "        return 'qa6_yes-no-questions_train.txt', 'qa6_yes-no-questions_test.txt'\n",
    "    if task_nr==10:\n",
    "        return 'qa10_indefinite-knowledge_train.txt', 'qa10_indefinite-knowledge_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedder=EmbeddingsPreparator()\n",
    "story_parser=StoryParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_tokens = embedder.get_unique_tokens([train_set_post_file, test_set_post_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_embedding = embedder.load_embedding_from_disks(\"glove.6B.50d.txt\",vocab_tokens, with_indexes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdoneva/anaconda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "train_stories=story_parser.get_stories(train_set_post_file, True)\n",
    "test_stories=story_parser.get_stories(test_set_post_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contexts_train, questions_train, answers_train = story_parser.vectorize_stories(train_stories, word_to_index)\n",
    "contexts_test, questions_test, answers_test = story_parser.vectorize_stories(test_stories, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts.shape = (1000,)\n",
      "questions.shape = (1000, 6)\n",
      "answers.shape = (1000, 27)\n"
     ]
    }
   ],
   "source": [
    "print('contexts.shape = {}'.format(contexts_train.shape))\n",
    "print('questions.shape = {}'.format(questions_train.shape))\n",
    "print('answers.shape = {}'.format(answers_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data = story_parser.get_final_dataset(contexts_train, questions_train, answers_train)\n",
    "final_test_data = story_parser.get_final_dataset(contexts_test, questions_test, answers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_ids = tf.placeholder(tf.float32, shape=[None,None,], name='context')  \n",
    "question_ids = tf.placeholder(tf.float32, shape=[None,None,], name='question')  \n",
    "true_answer= tf.placeholder(tf.float32, shape=[None,None], name='correct_answer')\n",
    "dimensions= index_to_embedding.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed=tf.keras.layers.Embedding(42,50)\n",
    "gru=tf.keras.layers.GRUCell(50)\n",
    "rnn=tf.keras.layers.RNN(gru)\n",
    "dropout=tf.keras.layers.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_embed = embed(context_ids)  \n",
    "quest_embed = embed(question_ids)\n",
    "\n",
    "encoded_sentence=rnn(context_embed)\n",
    "encoded_question=rnn(quest_embed)\n",
    "\n",
    "encoded_sentence=dropout(encoded_sentence)\n",
    "encoded_question=dropout(encoded_question)\n",
    "\n",
    "merged= tf.keras.layers.concatenate([encoded_sentence, encoded_question])\n",
    "\n",
    "preds = tf.keras.layers.Dense(dimensions, activation='softmax')(merged)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(true_answer, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.005).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_value = tf.keras.metrics.categorical_accuracy(true_answer, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 49.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: \n",
      "20.34594416618347\n",
      "Final Accuracy Score:\n",
      "0.564\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in tqdm(range(1000)):\n",
    "        batch = np.random.randint(final_train_data.shape[0], size=batch_size)\n",
    "        batch_data = final_train_data[batch]\n",
    "        feed = prep_batch(batch_data)\n",
    "        \n",
    "        train_step.run(feed_dict=feed)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Training time: ')\n",
    "    print(elapsed_time)\n",
    "    \n",
    "    print('Final Accuracy Score:')\n",
    "    test_data_feed=prep_batch(final_test_data)\n",
    "    print (np.mean(acc_value.eval(feed_dict=test_data_feed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_batch(batch_data):\n",
    "    contextsvs, questionsvs, answers=zip(*batch_data)\n",
    "    \n",
    "    #Pad to longest sequence in the batch \n",
    "    contexts = list(contextsvs)\n",
    "    max_context_length = max([len(x) for x in contexts])\n",
    "    questions = list(questionsvs)\n",
    "    max_query_length = max(len(x) for x in questionsvs)\n",
    "\n",
    "    final_contexts=pad_sequences(contextsvs, maxlen=max_context_length) \n",
    "    queries=pad_sequences(questionsvs, maxlen=max_query_length)\n",
    "    \n",
    "    feed = {context_ids: final_contexts,\n",
    "                  question_ids: queries,\n",
    "                  true_answer: answers}\n",
    "    \n",
    "    return feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
