{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.eager as tfe\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from itertools import chain\n",
    "from InputPreparator import EmbeddingsPreparator\n",
    "from InputPreparator import StoryParser\n",
    "import time\n",
    "\n",
    "#to avoid a warning from TF 1.7 version see https://github.com/tensorflow/tensorflow/issues/18111\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_task_files(task_nr):\n",
    "    if task_nr==5:\n",
    "        return 'qa5_three-arg-relations_train.txt', \"qa5_three-arg-relations_test.txt\"\n",
    "    if task_nr==6:\n",
    "        return 'qa6_yes-no-questions_train.txt', 'qa6_yes-no-questions_test.txt'\n",
    "    if task_nr==10:\n",
    "        return 'qa10_indefinite-knowledge_train.txt', 'qa10_indefinite-knowledge_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_file = get_task_files(5)[0]\n",
    "test_set_file = get_task_files(5)[0]\n",
    "\n",
    "train_set_post_file = \"data/tasks_1-20_v1-2/en/\"+train_set_file\n",
    "test_set_post_file = \"data/tasks_1-20_v1-2/en/\"+test_set_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedder=EmbeddingsPreparator()\n",
    "story_parser=StoryParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tokens = embedder.get_unique_tokens([train_set_post_file, test_set_post_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_embedding = embedder.load_embedding_from_disks(\"data/glove.6B.50d.txt\",vocab_tokens, with_indexes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories=story_parser.get_stories(train_set_post_file, True)\n",
    "test_stories=story_parser.get_stories(test_set_post_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contexts_train, questions_train, answers_train = story_parser.vectorize_stories(train_stories, word_to_index)\n",
    "contexts_test, questions_test, answers_test = story_parser.vectorize_stories(test_stories, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts.shape = (1000, 7)\n",
      "questions.shape = (1000,)\n",
      "answers.shape = (1000, 42)\n"
     ]
    }
   ],
   "source": [
    "print('contexts.shape = {}'.format(contexts_train.shape))\n",
    "print('questions.shape = {}'.format(questions_train.shape))\n",
    "print('answers.shape = {}'.format(answers_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_embedding.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data = story_parser.get_final_dataset(contexts_train, questions_train, answers_train)\n",
    "final_test_data = story_parser.get_final_dataset(contexts_test, questions_test, answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(data, all_data= False, train= False):\n",
    "    contextsvs, questionsvs, answers=zip(*data)\n",
    "    \n",
    "    #Pad to longest sequence in the batch \n",
    "    contexts = list(contextsvs)\n",
    "    max_context_length = max([len(x) for x in contexts])\n",
    "    questions = list(questionsvs)\n",
    "    max_query_length = max(len(x) for x in questionsvs)\n",
    "\n",
    "    final_contexts=pad_sequences(contextsvs, maxlen=max_context_length) \n",
    "    final_queries=pad_sequences(questionsvs, maxlen=max_query_length)\n",
    "    \n",
    "    return final_contexts, final_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_contexts, final_queries= prep_data(final_train_data)\n",
    "\n",
    "vocab_size= len(index_to_embedding)\n",
    "embed_dimensions= 50\n",
    "num_units_gru= 50\n",
    "keep_prob= 0.5\n",
    "q_shape= final_queries.shape[1]\n",
    "c_shape= final_contexts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         multiple             2100        input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rnn_3 (RNN)                     (None, 50)           15150       embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "rnn_4 (RNN)                     (None, 50)           15150       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           rnn_3[0][0]                      \n",
      "                                                                 rnn_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100)          0           dropout_2[0][0]                  \n",
      "                                                                 dropout_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 42)           4242        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,492\n",
      "Trainable params: 21,492\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_in = tf.keras.Input(shape=(q_shape,))\n",
    "c_in = tf.keras.Input(shape=(c_shape,))\n",
    "\n",
    "#embed\n",
    "embed = tf.keras.layers.Embedding(vocab_size, embed_dimensions)\n",
    "q = embed(q_in)\n",
    "c = embed(c_in)\n",
    "\n",
    "#encode\n",
    "grucell= tf.keras.layers.GRUCell(num_units_gru)\n",
    "c = tf.keras.layers.RNN(grucell)(c)\n",
    "q = tf.keras.layers.RNN(grucell)(q)\n",
    "\n",
    "#add dropout\n",
    "dropout= tf.keras.layers.Dropout(keep_prob)\n",
    "encoded_sentence= dropout(c)\n",
    "encoded_question= dropout(q)\n",
    "\n",
    "#merge\n",
    "merged= tf.keras.layers.concatenate([encoded_sentence, encoded_question])\n",
    "\n",
    "#predict\n",
    "pred=tf.keras.layers.Dense(answers_train.shape[1], activation=tf.nn.softmax)(merged)\n",
    "\n",
    "model = tf.keras.Model(inputs=[q_in, c_in], outputs=pred)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.3308 - acc: 0.8550\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 210us/step - loss: 0.3542 - acc: 0.8370\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.3408 - acc: 0.8430\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 199us/step - loss: 0.3298 - acc: 0.8600\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 187us/step - loss: 0.3355 - acc: 0.8540\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 203us/step - loss: 0.3283 - acc: 0.8560\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 0.3219 - acc: 0.8630\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.3386 - acc: 0.8590\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.3178 - acc: 0.8600\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 202us/step - loss: 0.3123 - acc: 0.8650\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 213us/step - loss: 0.3373 - acc: 0.8630\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 202us/step - loss: 0.3233 - acc: 0.8720\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 207us/step - loss: 0.3099 - acc: 0.8650\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 212us/step - loss: 0.3389 - acc: 0.8340\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 211us/step - loss: 0.3095 - acc: 0.8740\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.3052 - acc: 0.8750\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 207us/step - loss: 0.3175 - acc: 0.8550\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 205us/step - loss: 0.3265 - acc: 0.8620\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 0.3171 - acc: 0.8670\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 214us/step - loss: 0.3136 - acc: 0.8640\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 203us/step - loss: 0.3303 - acc: 0.8500\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 204us/step - loss: 0.3123 - acc: 0.8560\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 0.3170 - acc: 0.8530\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 213us/step - loss: 0.3261 - acc: 0.8580\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.3036 - acc: 0.8660\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 211us/step - loss: 0.3115 - acc: 0.8620\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.3007 - acc: 0.8790\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 0.3219 - acc: 0.8520\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 205us/step - loss: 0.3147 - acc: 0.8510\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 207us/step - loss: 0.3323 - acc: 0.8410\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 207us/step - loss: 0.3015 - acc: 0.8760\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 214us/step - loss: 0.3157 - acc: 0.8550\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 0.3100 - acc: 0.8570\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 218us/step - loss: 0.3228 - acc: 0.8520\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 0.3209 - acc: 0.8470\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 214us/step - loss: 0.3106 - acc: 0.8600\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 0.3070 - acc: 0.8640\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 218us/step - loss: 0.3024 - acc: 0.8670\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 201us/step - loss: 0.3202 - acc: 0.8650\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 0.3044 - acc: 0.8650\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.3031 - acc: 0.8730\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 210us/step - loss: 0.3211 - acc: 0.8530\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 0.2962 - acc: 0.8650 0s - loss: 0.2919 - acc: 0.865\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 0.2857 - acc: 0.8780\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 0.3073 - acc: 0.8680\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 0.3024 - acc: 0.8600\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 207us/step - loss: 0.3031 - acc: 0.8600\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.3029 - acc: 0.8660\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 0.2975 - acc: 0.8720\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 278us/step - loss: 0.2996 - acc: 0.8640\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 181us/step - loss: 0.2947 - acc: 0.8680\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.3028 - acc: 0.8560\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 221us/step - loss: 0.2926 - acc: 0.8710\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 204us/step - loss: 0.2933 - acc: 0.8680\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 193us/step - loss: 0.3023 - acc: 0.8640\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 191us/step - loss: 0.3159 - acc: 0.8530\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.2875 - acc: 0.8710\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 205us/step - loss: 0.3153 - acc: 0.8550\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.3044 - acc: 0.8620\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 191us/step - loss: 0.3076 - acc: 0.8660\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 186us/step - loss: 0.2885 - acc: 0.8710\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 218us/step - loss: 0.2976 - acc: 0.8700\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 185us/step - loss: 0.2975 - acc: 0.8660\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 190us/step - loss: 0.2847 - acc: 0.8710\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 0.2960 - acc: 0.8690\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 0.3123 - acc: 0.8540\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 183us/step - loss: 0.2981 - acc: 0.8650\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 177us/step - loss: 0.2774 - acc: 0.8770\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 186us/step - loss: 0.2781 - acc: 0.8750\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 193us/step - loss: 0.2790 - acc: 0.8800\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 221us/step - loss: 0.2874 - acc: 0.8770\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 177us/step - loss: 0.2948 - acc: 0.8750\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 186us/step - loss: 0.2850 - acc: 0.8720\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 175us/step - loss: 0.2960 - acc: 0.8750\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 181us/step - loss: 0.2967 - acc: 0.8590\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 194us/step - loss: 0.2942 - acc: 0.8760\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 173us/step - loss: 0.2833 - acc: 0.8780\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 169us/step - loss: 0.2834 - acc: 0.8660\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.3065 - acc: 0.8580\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 186us/step - loss: 0.2949 - acc: 0.8700\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.2724 - acc: 0.8860\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 170us/step - loss: 0.3007 - acc: 0.8650\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 173us/step - loss: 0.3098 - acc: 0.8660\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.2899 - acc: 0.8740\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 177us/step - loss: 0.3059 - acc: 0.8630\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.2826 - acc: 0.8680\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 189us/step - loss: 0.2711 - acc: 0.8810\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 169us/step - loss: 0.2916 - acc: 0.8700\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 190us/step - loss: 0.2909 - acc: 0.8670\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.2801 - acc: 0.8740\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.2757 - acc: 0.8840\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 214us/step - loss: 0.2811 - acc: 0.8660\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 194us/step - loss: 0.2942 - acc: 0.8690\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 183us/step - loss: 0.2902 - acc: 0.8680\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 190us/step - loss: 0.2780 - acc: 0.8760\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 175us/step - loss: 0.2744 - acc: 0.8800\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 187us/step - loss: 0.2863 - acc: 0.8640\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 169us/step - loss: 0.2782 - acc: 0.8770\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 182us/step - loss: 0.2906 - acc: 0.8680\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 193us/step - loss: 0.2830 - acc: 0.8620\n",
      "Training time: \n",
      "20.10834503173828\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training...')\n",
    "start_time = time.time()\n",
    "model.fit([final_queries, final_contexts], answers_train, epochs=100, batch_size=128)\n",
    "elapsed_time = time.time() - start_time\n",
    "print()\n",
    "print('Training time: ')\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_test, final_queries_test= prep_data(final_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 79us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([final_queries_test,final_context_test], answers_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20600797593593598, 0.8820000004768371]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
