{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdoneva/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from itertools import chain\n",
    "from InputPreparator import EmbeddingsPreparator\n",
    "from InputPreparator import StoryParser\n",
    "import csv\n",
    "\n",
    "#to avoid a warning from TF 1.7 version see https://github.com/tensorflow/tensorflow/issues/18111\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store relevant data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_task_files(task_nr):\n",
    "    if task_nr==5:\n",
    "        return 'qa5_three-arg-relations_train.txt', \"qa5_three-arg-relations_test.txt\"\n",
    "    if task_nr==6:\n",
    "        return 'qa6_yes-no-questions_train.txt', 'qa6_yes-no-questions_test.txt'\n",
    "    if task_nr==10:\n",
    "        return 'qa10_indefinite-knowledge_train.txt', 'qa10_indefinite-knowledge_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_file = get_task_files(10)[0]\n",
    "test_set_file = get_task_files(10)[1]\n",
    "\n",
    "train_set_post_file = \"data/tasks_1-20_v1-2/en/\"+train_set_file\n",
    "test_set_post_file = \"data/tasks_1-20_v1-2/en/\"+test_set_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedder=EmbeddingsPreparator()\n",
    "story_parser=StoryParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tokens = embedder.get_unique_tokens([train_set_post_file, test_set_post_file])\n",
    "word_to_index, index_to_embedding = embedder.load_embedding_from_disks(\"data/glove.6B.50d.txt\",vocab_tokens, with_indexes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories=story_parser.get_stories(train_set_post_file, True)\n",
    "test_stories=story_parser.get_stories(test_set_post_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store into a csv file: per row (context, question, answer)\n",
    "def store_to_csv(data, filename, vectors):\n",
    "    with open(filename,'w') as f:   \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['context', 'question', 'answer'])\n",
    "        for story in data:\n",
    "            if vectors:\n",
    "                writer.writerow(story)\n",
    "            else:\n",
    "                temp=[]\n",
    "                context, question, answer= story\n",
    "                temp.append(' '.join(context))\n",
    "                temp.append(' '.join(question))\n",
    "                temp.append(''.join(answer))            \n",
    "                writer.writerow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_to_csv(train_stories, 'train_data.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(sentence, answer, word_to_index):\n",
    "    if not answer:\n",
    "        x=[]\n",
    "        for w in sentence.split():\n",
    "            w=w.lower().strip()\n",
    "            #print(w)\n",
    "            x.append(word_to_index[w]) \n",
    "        return x\n",
    "     \n",
    "    else:\n",
    "        # The Answer is one-hot encoded in our vocabulary matrix\n",
    "        y = np.zeros(len(word_to_index) + 1, dtype=int)\n",
    "        answ=sentence.lower().strip()\n",
    "        y[word_to_index[answ]] = 1\n",
    "        return y      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convert via TFRecords\n",
    "- https://medium.com/@TalPerry/getting-text-into-tensorflow-with-the-dataset-api-ffb832c8bec6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_to_tf_example(context, question, answer):\n",
    "        context_ids= vectorize(context, False, word_to_index)\n",
    "        question_ids= vectorize(question, False, word_to_index)\n",
    "        answer_ids= vectorize(answer, True, word_to_index)\n",
    "        ex = tf.train.SequenceExample()\n",
    "      \n",
    "        context_tokens = ex.feature_lists.feature_list[\"context\"]\n",
    "        question_tokens = ex.feature_lists.feature_list[\"question\"]\n",
    "        answer_tokens = ex.feature_lists.feature_list[\"answer\"]\n",
    "        \n",
    "        for token in context_ids:\n",
    "            context_tokens.feature.add().int64_list.value.append(token)\n",
    "        for token in question_ids:\n",
    "            question_tokens.feature.add().int64_list.value.append(token)\n",
    "        for token in answer_ids:\n",
    "            #print(token)\n",
    "            answer_tokens.feature.add().int64_list.value.append(token)\n",
    "\n",
    "        return ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sequence_to_tf_example(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_from_tfrecord(ex):\n",
    "    '''\n",
    "    Explain to TF how to go from a serialized example back to tensors\n",
    "    '''\n",
    "    sequence_features = {\n",
    "        \"context\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"question\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"answer\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse the example (returns a dictionary of tensors)\n",
    "    _, sequence_parsed = tf.parse_single_sequence_example(\n",
    "        serialized=ex,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "\n",
    "    return {\"context\": sequence_parsed['context'], \"question\": sequence_parsed['question'],\n",
    "            \"answer\": sequence_parsed['answer']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_tfrecord(context, question, answer, tfrecord_file, writer):\n",
    "    example= sequence_to_tf_example(context, question, answer)\n",
    "    #print(example)\n",
    "    writer.write(example.SerializeToString())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train_data.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    next(readCSV) #skip header\n",
    "    writer= tf.python_io.TFRecordWriter('train.tfrecords')\n",
    "    for row in readCSV:\n",
    "        write_to_tfrecord(row[0], row[1], row[2],'train.tfrecords',writer)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(path, batch_size=128):\n",
    "    '''\n",
    "    Makes  a Tensorflow dataset that is shuffled, batched and parsed.\n",
    "    :param path: The path to a tf record file\n",
    "    :batch size: The size of our batch\n",
    "    :return: a Dataset that shuffles and is padded\n",
    "    '''\n",
    "    # Read a tf record file. This makes a dataset of raw TFRecords\n",
    "    dataset = tf.data.TFRecordDataset([path])\n",
    "    # Apply/map the parse function to every record. Now the dataset is a bunch of dictionaries of Tensors\n",
    "    dataset =  dataset.map(read_from_tfrecord)\n",
    "    #Shuffle the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "   \n",
    "    # specify padding for each tensor seperatly\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes={\n",
    "        \"context\": tf.TensorShape([None]), \n",
    "        \"question\": tf.TensorShape([None]), \n",
    "        \"answer\": tf.TensorShape([None]) \n",
    "    })\n",
    "   \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tfrecords= make_dataset('train.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eager Execution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "vocab_size= len(index_to_embedding)\n",
    "embed_dimensions= 50\n",
    "num_units_gru= 50\n",
    "keep_prob= 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embed=tf.keras.layers.Embedding(vocab_size,embed_dimensions)\n",
    "        self.grucell=tf.keras.layers.GRUCell(num_units_gru)\n",
    "        self.rnn=tf.keras.layers.RNN(self.grucell)\n",
    "        self.dense=tf.keras.layers.Dense(answers_train.shape[1], activation=tf.nn.softmax)\n",
    "        self.dropout=tf.keras.layers.Dropout(keep_prob)\n",
    "        self.permute=tf.keras.layers.Permute((2,1), input_shape=(None, None))\n",
    "\n",
    "        \n",
    "    def predict(self, sentence, question):\n",
    "        encoded_sentence=self.embed(sentence)\n",
    "        #print(encoded_sentence)\n",
    "        #encoded_sentence=tf.keras.backend.expand_dims(encoded_sentence, axis=-1)  \n",
    "        encoded_sentence=self.rnn(encoded_sentence)\n",
    "        encoded_sentence=self.dropout(encoded_sentence)\n",
    "        \n",
    "        encoded_question=self.embed(question)\n",
    "        #encoded_question=tf.keras.backend.expand_dims(encoded_question, axis=-1)\n",
    "        encoded_question=self.rnn(encoded_question)\n",
    "        encoded_question=self.dropout(encoded_question)\n",
    "        #encoded_question=tf.keras.backend.expand_dims(encoded_question, axis=-1)\n",
    "        #encoded_question=self.permute(encoded_question)\n",
    "        \n",
    "        merged= tf.keras.layers.concatenate([encoded_sentence, encoded_question])\n",
    "        pred= self.dense(merged)\n",
    "        #pred= tf.keras.backend.expand_dims(pred, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(model, sent, quest, y):\n",
    "    prediction = model.predict(sent, quest)\n",
    "    return tf.keras.losses.categorical_crossentropy(y, prediction)\n",
    "\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad(model, sent, quest, targets):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_value = loss(model, sent, quest, targets)\n",
    "        tf.contrib.summary.scalar(\"loss\", loss_value)\n",
    "    return tape.gradient(loss_value, model.variables), loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global_step = tf.train.get_or_create_global_step() \n",
    "#summary_writer = tf.contrib.summary.create_file_writer('log/eager', flush_millis=10000) \n",
    "#with summary_writer.as_default():\n",
    "#    tf.contrib.summary.always_record_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[32,0] = 28 is not in [0, 27) [Op:Gather]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-2a40d0785774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         optimizer.apply_gradients(zip(grads, model.variables),\n\u001b[1;32m     11\u001b[0m                             global_step=tf.train.get_or_create_global_step())\n",
      "\u001b[0;32m<ipython-input-44-5a546c844e4a>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, sent, quest, targets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-a451cfb98972>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(model, sent, quest, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#return tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-dc817c7db00c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentence, question)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mencoded_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print(encoded_sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#encoded_sentence=tf.keras.backend.expand_dims(encoded_sentence, axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(reference, indices)\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m   \"\"\"\n\u001b[0;32m-> 1496\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(params, indices, validate_indices, name, axis)\u001b[0m\n\u001b[1;32m   2696\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m     return gen_array_ops.gather(\n\u001b[0;32m-> 2698\u001b[0;31m         params, indices, validate_indices=validate_indices, name=name)\n\u001b[0m\u001b[1;32m   2699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(params, indices, validate_indices, name)\u001b[0m\n\u001b[1;32m   2695\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sdoneva/anaconda/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[32,0] = 28 is not in [0, 27) [Op:Gather]"
     ]
    }
   ],
   "source": [
    "model=Model()\n",
    "\n",
    "for i in range(100):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    epoch_accuracy = tfe.metrics.Accuracy()\n",
    "    for batch in tfe.Iterator(data): # 8 batches\n",
    "        answer = tf.keras.backend.cast(batch['answer'], 'float32')\n",
    "\n",
    "        grads, loss_value = grad(model, batch['context'], batch['question'], answer)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                            global_step=tf.train.get_or_create_global_step())\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
    "        #i=i+1\n",
    "        #print(np.mean(loss_value))\n",
    "        #print(tf.reduce_mean(loss(model, example['context'], example['ques'] , a_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
