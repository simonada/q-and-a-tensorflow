{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import json \n",
    "import hashlib\n",
    "import re\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from itertools import chain\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from InputPreparator import EmbeddingsPreparator\n",
    "from InputPreparator import StoryParser\n",
    "\n",
    "#to avoid a warning from TF 1.7 version see https://github.com/tensorflow/tensorflow/issues/18111\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the data was not imported from GitHub, it can be downloaded from the links below. Please unzip them in a 'data' folder:\n",
    "- GloVe: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "- babI tasks: https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task selection. This project was realized for 3 of the 20 babI tasks:\n",
    "- TASK_NUMBER: to test different tasks (5, 6 or 10), \n",
    "- SUPPORTING_ONLY: to test different versions (with whole context or only the supporting sentence)\n",
    "- USE_PRETRAINED: if you want to load pre-trained model parameters instead of training. This will load the best performing parameters that were computed for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TASK_NUMBER = 10\n",
    "SUPPORTING_ONLY = True\n",
    "USE_PRETRAINED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_task_files(task_nr):\n",
    "    if task_nr==5:\n",
    "        return 'qa5_three-arg-relations_train.txt', \"qa5_three-arg-relations_test.txt\"\n",
    "    if task_nr==6:\n",
    "        return 'qa6_yes-no-questions_train.txt', 'qa6_yes-no-questions_test.txt'\n",
    "    if task_nr==10:\n",
    "        return 'qa10_indefinite-knowledge_train.txt', 'qa10_indefinite-knowledge_test.txt'\n",
    "    else:\n",
    "        print('No such task number. Please extend the code correspondingly if required.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_file = get_task_files(TASK_NUMBER)[0]\n",
    "test_set_file = get_task_files(TASK_NUMBER)[1]\n",
    "\n",
    "train_set_post_file = \"data/tasks_1-20_v1-2/en/\"+train_set_file\n",
    "test_set_post_file = \"data/tasks_1-20_v1-2/en/\"+test_set_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedder=EmbeddingsPreparator()\n",
    "story_parser=StoryParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input preparation\n",
    "- Since the input preparation logic is shared among several models, the logic was encapsulated into a separate InputPreparator.py file, which was imported as a module in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "-> ref. https://github.com/guillaume-chevalier/GloVe-as-a-TensorFlow-Embedding-Layer\n",
    "- The code was adjusted to be able to work with only a set of words (based on the corpus vocabulary) we want to keep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_tokens = embedder.get_unique_tokens([train_set_post_file, test_set_post_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_embedding = embedder.load_embedding_from_disks(\"data/glove.6B.50d.txt\",vocab_tokens, with_indexes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_word = dict((val, key) for key, val in word_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_by_index(index):\n",
    "    return index_to_word[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_to_words(indices):\n",
    "    words=[]\n",
    "    for w_id in indices:\n",
    "        if w_id != 0:\n",
    "            words.append(index_to_word[w_id]) \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "-> ref. https://github.com/keras-team/keras/blob/master/examples/babi_rnn.py\n",
    "- \"get_stories\": returns tokenized (context, question, answer) triples. The boolean parameter indicates whether to keep all sentences in the context (False) or only the supporting one (True)\n",
    "- \"vectorize_stories\": encodes the tokens into a sequence of ids for the embeddings look up\n",
    "- \"get_final_dataset\": context, question and answer are zipped together to represent a single story, i.e. single train/test example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stories=story_parser.get_stories(train_set_post_file, SUPPORTING_ONLY)\n",
    "test_stories=story_parser.get_stories(test_set_post_file, SUPPORTING_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(train_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sl = slice(0, 200)\n",
    "valid_stories= train_stories[sl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = slice(200, 1000)\n",
    "train_stories= train_stories[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contexts_train, questions_train, answers_train = story_parser.vectorize_stories(train_stories, word_to_index)\n",
    "contexts_test, questions_test, answers_test = story_parser.vectorize_stories(test_stories, word_to_index)\n",
    "contexts_valid, questions_valid, answers_valid = story_parser.vectorize_stories(valid_stories, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts.shape = (800,)\n",
      "questions.shape = (800, 6)\n",
      "answers.shape = (800, 27)\n"
     ]
    }
   ],
   "source": [
    "print('contexts.shape = {}'.format(contexts_train.shape))\n",
    "print('questions.shape = {}'.format(questions_train.shape))\n",
    "print('answers.shape = {}'.format(answers_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data = story_parser.get_final_dataset(contexts_train, questions_train, answers_train)\n",
    "final_test_data = story_parser.get_final_dataset(contexts_test, questions_test, answers_test)\n",
    "final_valid_data = story_parser.get_final_dataset(contexts_valid, questions_valid, answers_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_train_data.shape = (800, 3)\n",
      "final_test_data.shape = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print('final_train_data.shape = {}'.format(final_train_data.shape))\n",
    "print('final_test_data.shape = {}'.format(final_test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model: Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128  \n",
    "display_step = 20 # How many iterations of training occur before each validation check.\n",
    "vocab_size= len(index_to_embedding)\n",
    "keep_prob_train= 0.5\n",
    "num_epochs= 200 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model: Assembling the graph\n",
    "- for the model structure approach ref. http://web.stanford.edu/class/cs20si/lectures/notes_04.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Defining placeholders for the inputs\n",
    "- Tensor shapes for contexts and questions are set to None (can feed any tensor) since the first dimension depends on the batch size, which is padded depending on the longest sentence in the batch, and the second dimension depends on the corpus words, which varies among different task datasets\n",
    "- Global step is used to append the number of training steps the model has gone through. It is passed as parameter to the optimizer and increased during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_ids = tf.placeholder('int32', shape=[None, None,], name= 'context')  \n",
    "question_ids = tf.placeholder('int32', shape=[None, None,], name= 'question')  \n",
    "answer_encoded=tf.placeholder('int32', shape=[None, vocab_size], name= 'correct_answer')\n",
    "tf_embedding_placeholder = tf.placeholder(tf.float32, shape= index_to_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 Defining the weights/ hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate= tf.constant(0.001)\n",
    "# Dropout should only be active during training\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "num_units_gru= 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3  Inference (forward path of the graph)\n",
    "-> Ref. for the Model architecture/idea:\n",
    "- https://github.com/keras-team/keras/blob/master/examples/babi_rnn.py\n",
    "- http://smerity.com/articles/2015/keras_qa.html\n",
    "- http://cs224d.stanford.edu/reports/StrohMathur.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the variable that will hold the embedding:\n",
    "with tf.variable_scope('embeddings'):\n",
    "\n",
    "    tf_embedding = tf.Variable(\n",
    "        tf.constant(0.0, shape=index_to_embedding.shape),\n",
    "        trainable=False,\n",
    "        name=\"embedding\"\n",
    "    )\n",
    "    \n",
    "    tf_embedding_init = tf_embedding.assign(tf_embedding_placeholder)\n",
    "    \n",
    "    encoded_context= tf.nn.embedding_lookup(\n",
    "        params=tf_embedding,\n",
    "        ids=context_ids\n",
    "    )\n",
    "    encoded_question= tf.nn.embedding_lookup(\n",
    "        params=tf_embedding,\n",
    "        ids=question_ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru = tf.contrib.rnn.GRUCell(num_units_gru)\n",
    "\n",
    "with tf.variable_scope('rnn_context'):\n",
    "    rnn_outputs_context, final_state_c = tf.nn.dynamic_rnn (gru, encoded_context, dtype=tf.float32)\n",
    "         # Obtain the last relevant output and add dropout to avoid overfitting\n",
    "    final_state_c = tf.layers.dropout(final_state_c, keep_prob)\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(50):\n",
    "        tf.summary.histogram('rnn_out_context', final_state_c)  # for TensorBoard  \n",
    "\n",
    "with tf.variable_scope('rnn_question'):   \n",
    "    rnn_outputs_question, final_state_q = tf.nn.dynamic_rnn (gru, encoded_question, dtype=tf.float32)\n",
    "         # Obtain the last relevant output and add dropout to avoid overfitting\n",
    "    final_state_q = tf.layers.dropout(final_state_q, keep_prob)\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(50):\n",
    "        tf.summary.histogram('rnn_out_question', final_state_q) # for TensorBoard  \n",
    "    \n",
    "with tf.variable_scope('dense_softmax'):\n",
    "    merged= tf.concat([final_state_c,final_state_q],1)\n",
    "        #use the output to make prediction on the answer word\n",
    "    pred = tf.layers.dense(inputs=merged, units=vocab_size, activation=tf.nn.softmax)    \n",
    "    \n",
    "    #used for visualization in 'visualize_wrong_predictions'\n",
    "    prediction=tf.argmax(pred,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4 Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=answer_encoded)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(50):\n",
    "        tf.summary.scalar(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5 Defining the optimizer and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train_adam'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    opt_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('accuracy'):\n",
    "    predicts = tf.cast(tf.argmax(pred, 1), 'int32')\n",
    "    corrects = tf.equal(predicts, tf.cast(tf.argmax(answer_encoded, 1), 'int32'))\n",
    "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(50):\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #6 Prepare for visualization in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_writers(sess):\n",
    "    train_writer = tf.summary.FileWriter('log' + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('log' + '/validation')\n",
    "    \n",
    "    return train_writer, test_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_embeddings(sess):\n",
    "    \n",
    "    with open('log/metadata.tsv','w') as f:\n",
    "        f.write(\"Index\\tLabel\\n\")\n",
    "        for key, val in word_to_index.items():\n",
    "            f.write(\"%d\\t%s\\n\" % (int(val),key))\n",
    "        f.write(\"%d\\t%s\\n\" % (int(vocab_size),'unknown'))\n",
    "\n",
    "    embed_writer = tf.summary.FileWriter('log', sess.graph)\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_conf = config.embeddings.add()\n",
    "    embedding_conf.tensor_name = tf_embedding.name\n",
    "    embedding_conf.metadata_path = os.path.join('metadata.tsv')\n",
    "    projector.visualize_embeddings(embed_writer, config)\n",
    "\n",
    "    saver.save(sess, os.path.join('log', \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model : Executing the computation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_validation_set():   \n",
    "    return prep_batch(final_valid_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Note\n",
    "- the sequences are padded to the length of the longest sequence in the batch\n",
    "- we don't want to apply dropout when testing- set keep_prob only in the training feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_batch(batch_data, all_data= False, train= False):\n",
    "    contextsvs, questionsvs, answers=zip(*batch_data)\n",
    "    \n",
    "    #Pad to longest sequence in the batch \n",
    "    contexts = list(contextsvs)\n",
    "    max_context_length = max([len(x) for x in contexts])\n",
    "    questions = list(questionsvs)\n",
    "    max_query_length = max(len(x) for x in questionsvs)\n",
    "\n",
    "    final_contexts=pad_sequences(contextsvs, maxlen=max_context_length) \n",
    "    queries=pad_sequences(questionsvs, maxlen=max_query_length)\n",
    "    \n",
    "    if train:\n",
    "        feed = {context_ids: final_contexts,\n",
    "                  question_ids: queries,\n",
    "                  answer_encoded: answers,\n",
    "                  keep_prob:keep_prob_train}\n",
    "    else:\n",
    "        feed = {context_ids: final_contexts,\n",
    "                  question_ids: queries,\n",
    "                  answer_encoded: answers}\n",
    "    \n",
    "    return (feed, final_contexts, queries, answers) if all_data else feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_with_epochs(sess, epochs, batch_size, final_train_data, merged_summaries, train_writer, test_writer):\n",
    "\n",
    "    #Get valid set\n",
    "    validation_set, val_contexts, val_queries, val_answers = prep_validation_set()\n",
    "        \n",
    "    for i in tqdm(range(epochs)):\n",
    "        \n",
    "        train_count= final_train_data.shape[0]//batch_size\n",
    "\n",
    "        for step in range(train_count):\n",
    "\n",
    "            end = min((step+1)*batch_size, final_train_data.shape[0])\n",
    "            sample= final_train_data[step*batch_size:end,:]\n",
    "            feed=prep_batch(sample, False, True)  \n",
    "\n",
    "            _,summaries_res= sess.run(\n",
    "              [opt_op, merged_summaries], feed_dict=feed) \n",
    "            \n",
    "            train_writer.add_summary(summaries_res, i)\n",
    "        \n",
    "        if i % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            tmp_loss, acc, summaries_test= sess.run([loss, accuracy, merged_summaries], feed_dict=validation_set)       \n",
    "            test_writer.add_summary(summaries_test, i)           \n",
    "            # Display results\n",
    "            print(\"Epoch \" + str(i),\", Validation Set Loss= \", tmp_loss,\n",
    "                  \"Validation Set Accuracy= \", np.mean(acc))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore_best_model_parameters(sess, model_version):\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./restore/tf_layers/\"+get_best_model(model_version))\n",
    "    print(\"Model restored.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(model_version):\n",
    "    if SUPPORTING_ONLY:      \n",
    "        if TASK_NUMBER == 5:\n",
    "            best = model_version + '_3.ckpt'\n",
    "        elif TASK_NUMBER == 6:\n",
    "            best = model_version + '_3.ckpt'\n",
    "        else:\n",
    "            best = model_version + '_2.ckpt'\n",
    "    else:\n",
    "        if TASK_NUMBER == 5:\n",
    "            best = model_version + '_2.ckpt'\n",
    "        elif TASK_NUMBER == 6:\n",
    "            best = model_version + '_3.ckpt'\n",
    "        else:\n",
    "            best = model_version + '_2.ckpt'\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this function we fetch:\n",
    "- prediction: vector of ids of the predicted words, converted to the word for visualization\n",
    "- corrects: boolean vector whether the prediction was correct. We loop over it, and if false, based on the index extract the corresponding sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_wrong_predictions(sess, show=True):\n",
    "    validation_set, val_contexts, val_queries, val_answers = prep_validation_set()\n",
    "\n",
    "    pred, correct= sess.run([prediction, corrects], feed_dict=validation_set)    \n",
    "    answers=np.argmax(val_answers,1)   \n",
    "    count=0\n",
    "    #print(pred, correct)\n",
    "            \n",
    "    for i in range(len(pred)):\n",
    "        if not correct[i]:\n",
    "            if show:\n",
    "                print(\"TEXT: \", ' '.join(index_to_words(val_contexts[i])))\n",
    "                print (\"QUESTION: \", ' '.join(index_to_words(val_queries[i])))\n",
    "                print (\"RESPONSE: \", get_word_by_index(pred[i]))\n",
    "                print(\"EXPECTED: \", get_word_by_index(answers[i]))\n",
    "                print()\n",
    "            count=count+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used when saving the model\n",
    "def get_model_version():\n",
    "    task_nr = str(TASK_NUMBER)\n",
    "    name= 'task_' + task_nr+\"_\"\n",
    "    if SUPPORTING_ONLY:\n",
    "        name=name+\"reduced\"\n",
    "    else:\n",
    "        name=name+\"whole\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a Session: Train or Restore pretrained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_version= get_model_version()\n",
    "saver= tf.train.Saver()\n",
    "if not os.path.exists('./save/tf_layers/'):\n",
    "    os.makedirs('./save/tf_layers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    saver= tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        sess.run(tf.global_variables_initializer())  \n",
    "        \n",
    "    # load embeddings matrix\n",
    "        _ = sess.run(\n",
    "            tf_embedding_init, \n",
    "            feed_dict={tf_embedding_placeholder: index_to_embedding\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    # prepare visualization setup\n",
    "    # save the model\n",
    "        merged_summaries = tf.summary.merge_all()\n",
    "        train_writer, test_writer= init_writers(sess)\n",
    "        log_embeddings(sess)\n",
    "    \n",
    "    #Train, Visualize and Validate\n",
    "        print('Training...')\n",
    "        start_time = time.time()\n",
    "        train_with_epochs(sess, num_epochs, batch_size, final_train_data, merged_summaries, train_writer, test_writer)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Training time: ')\n",
    "        print(elapsed_time)\n",
    "\n",
    "        print()\n",
    "        print('Final Testing Accuracy:')\n",
    "        print(np.mean(sess.run([accuracy], feed_dict= prep_batch(final_test_data))[0]))\n",
    "        \n",
    "        #comment out if you want to save the model:\n",
    "        #save_path = saver.save(sess, \"./save/tf_layers/\"+model_version+'_1.ckpt')\n",
    "        #print(\"Model saved in path: %s\" % save_path)\n",
    "        #print()\n",
    "        \n",
    "    #Visualize wrong predictions\n",
    "        count=visualize_wrong_predictions(sess, False)\n",
    "        print('Visualizing '+str(count)+ ' incorrect predictions from validation dataset:')\n",
    "        visualize_wrong_predictions(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_pretrained_model():\n",
    "    with tf.Session() as sess:\n",
    "        restore_best_model_parameters(sess, model_version)\n",
    "        print(\"Accuracy on test data:\")\n",
    "        print(np.mean(sess.run([accuracy], feed_dict= prep_batch(final_test_data))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:00<01:02,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , Validation Set Loss=  3.2363207 Validation Set Accuracy=  0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:02<00:20,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 , Validation Set Loss=  2.8436499 Validation Set Accuracy=  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [00:04<00:17,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 , Validation Set Loss=  2.8075123 Validation Set Accuracy=  0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [00:06<00:14,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 , Validation Set Loss=  2.768124 Validation Set Accuracy=  0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [00:08<00:12,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 , Validation Set Loss=  2.752107 Validation Set Accuracy=  0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/200 [00:10<00:09,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 , Validation Set Loss=  2.7386274 Validation Set Accuracy=  0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 122/200 [00:12<00:07,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 , Validation Set Loss=  2.7301252 Validation Set Accuracy=  0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 142/200 [00:14<00:06,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 , Validation Set Loss=  2.726706 Validation Set Accuracy=  0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 162/200 [00:17<00:04,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 , Validation Set Loss=  2.7255785 Validation Set Accuracy=  0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 182/200 [00:19<00:01,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 , Validation Set Loss=  2.7304146 Validation Set Accuracy=  0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: \n",
      "20.99116611480713\n",
      "\n",
      "Final Testing Accuracy:\n",
      "0.679\n",
      "Visualizing 74 incorrect predictions from validation dataset:\n",
      "TEXT:  fred is either in the office or the office .\n",
      "QUESTION:  is fred in the office ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  fred went to the park .\n",
      "QUESTION:  is fred in the school ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary journeyed to the park .\n",
      "QUESTION:  is mary in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred went back to the park .\n",
      "QUESTION:  is fred in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary travelled to the cinema .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  fred travelled to the park .\n",
      "QUESTION:  is fred in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is in the park .\n",
      "QUESTION:  is bill in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie is in the office .\n",
      "QUESTION:  is julie in the school ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is in the school .\n",
      "QUESTION:  is bill in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred is either in the office or the cinema .\n",
      "QUESTION:  is fred in the office ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  bill travelled to the cinema .\n",
      "QUESTION:  is bill in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  mary is in the cinema .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  mary is in the park .\n",
      "QUESTION:  is mary in the school ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is either in the park or the kitchen .\n",
      "QUESTION:  is bill in the park ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  julie is either in the bedroom or the office .\n",
      "QUESTION:  is julie in the kitchen ?\n",
      "RESPONSE:  maybe\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie went to the park .\n",
      "QUESTION:  is julie in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred is in the office .\n",
      "QUESTION:  is fred in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary is either in the park or the office .\n",
      "QUESTION:  is mary in the park ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  fred is either in the school or the cinema .\n",
      "QUESTION:  is fred in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  mary is either in the cinema or the school .\n",
      "QUESTION:  is mary in the school ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  julie is in the school .\n",
      "QUESTION:  is julie in the park ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is in the kitchen .\n",
      "QUESTION:  is bill in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary travelled to the bedroom .\n",
      "QUESTION:  is mary in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary journeyed to the cinema .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  mary is in the park .\n",
      "QUESTION:  is mary in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie is in the office .\n",
      "QUESTION:  is julie in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred went back to the park .\n",
      "QUESTION:  is fred in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred travelled to the office .\n",
      "QUESTION:  is fred in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill went to the office .\n",
      "QUESTION:  is bill in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary went to the school .\n",
      "QUESTION:  is mary in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie went back to the school .\n",
      "QUESTION:  is julie in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred went to the kitchen .\n",
      "QUESTION:  is fred in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary is either in the cinema or the kitchen .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  mary journeyed to the cinema .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  fred travelled to the office .\n",
      "QUESTION:  is fred in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is either in the park or the office .\n",
      "QUESTION:  is bill in the park ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  fred is either in the school or the park .\n",
      "QUESTION:  is fred in the school ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  julie went to the park .\n",
      "QUESTION:  is julie in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill went to the cinema .\n",
      "QUESTION:  is bill in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  fred is either in the office or the office .\n",
      "QUESTION:  is fred in the office ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  julie is in the cinema .\n",
      "QUESTION:  is julie in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  bill moved to the cinema .\n",
      "QUESTION:  is bill in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  julie is in the cinema .\n",
      "QUESTION:  is julie in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  julie journeyed to the park .\n",
      "QUESTION:  is julie in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is in the cinema .\n",
      "QUESTION:  is bill in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  julie is either in the office or the kitchen .\n",
      "QUESTION:  is julie in the office ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  bill went back to the office .\n",
      "QUESTION:  is bill in the park ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred went back to the park .\n",
      "QUESTION:  is fred in the school ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie is in the school .\n",
      "QUESTION:  is julie in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred is in the park .\n",
      "QUESTION:  is fred in the school ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred went back to the school .\n",
      "QUESTION:  is fred in the park ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred is in the school .\n",
      "QUESTION:  is fred in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is either in the park or the office .\n",
      "QUESTION:  is bill in the park ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  bill moved to the bedroom .\n",
      "QUESTION:  is bill in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred went to the park .\n",
      "QUESTION:  is fred in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie is either in the cinema or the office .\n",
      "QUESTION:  is julie in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  bill is in the bedroom .\n",
      "QUESTION:  is bill in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary is in the school .\n",
      "QUESTION:  is mary in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is in the school .\n",
      "QUESTION:  is bill in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie moved to the cinema .\n",
      "QUESTION:  is julie in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  bill travelled to the park .\n",
      "QUESTION:  is bill in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary is in the cinema .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  fred travelled to the park .\n",
      "QUESTION:  is fred in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary travelled to the park .\n",
      "QUESTION:  is mary in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  julie is in the park .\n",
      "QUESTION:  is julie in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary is in the park .\n",
      "QUESTION:  is mary in the office ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  fred journeyed to the cinema .\n",
      "QUESTION:  is fred in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  mary is in the office .\n",
      "QUESTION:  is mary in the bedroom ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary journeyed to the cinema .\n",
      "QUESTION:  is mary in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  bill is either in the park or the bedroom .\n",
      "QUESTION:  is bill in the office ?\n",
      "RESPONSE:  maybe\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  bill is either in the school or the office .\n",
      "QUESTION:  is bill in the school ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  maybe\n",
      "\n",
      "TEXT:  fred is in the cinema .\n",
      "QUESTION:  is fred in the cinema ?\n",
      "RESPONSE:  no\n",
      "EXPECTED:  yes\n",
      "\n",
      "TEXT:  bill went back to the school .\n",
      "QUESTION:  is bill in the park ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n",
      "TEXT:  mary went to the school .\n",
      "QUESTION:  is mary in the kitchen ?\n",
      "RESPONSE:  yes\n",
      "EXPECTED:  no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if USE_PRETRAINED:\n",
    "    test_pretrained_model()\n",
    "else:\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
